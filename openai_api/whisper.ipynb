{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e136a5a2-64bf-48dc-a87b-dbf47ae8f415",
   "metadata": {},
   "source": [
    "# 快速入门 语音识别模型 Whisper \n",
    "\n",
    "OpenAI 提供了两个基于开源的 Whisper large-v2 模型的语音到文本API服务：\n",
    "- 转录（transcriptions）：将音频转录为音频所使用的任何语言。\n",
    "- 翻译（translations）：将音频翻译并转录为英语\n",
    "\n",
    "\n",
    "目前文件上传限制为 25 MB，支持以下输入文件类型：`mp3、mp4、mpeg、mpga、m4a、wav 和 webm`。\n",
    "\n",
    "\n",
    "## 语音转录 Transcription API\n",
    "\n",
    "输入音频文件，返回转录对象（JSON）\n",
    "\n",
    "参数\n",
    "- **file**（文件）：需要转录的音频文件对象（不是文件名），支持以下格式：flac、mp3、mp4、mpeg、mpga、m4a、ogg、wav 或 webm。\n",
    "- **model**（'whisper-1'）：使用的模型 ID。目前仅可使用由我们的开源 Whisper V2 模型驱动的 whisper-1。\n",
    "- **language**（语言，可选）：输入音频的语言。提供 ISO-639-1 格式的输入语言可以提高准确性和响应速度。\n",
    "- **prompt**（提示，可选）：可选文本，用于指导模型的风格或继续前一个音频片段。提示应与音频语言相匹配。\n",
    "- **response_format**（响应格式，可选）：转录输出的格式，默认为 json。可选的格式有：json、text、srt、verbose_json 或 vtt。\n",
    "- **temperature**（温度，可选）：采样温度，范围从 0 到 1。更高的值，如 0.8，将使输出更随机，而更低的值，如 0.2，将使输出更集中和确定。如果设置为 0，模型将使用对数概率自动提高温度，直到达到某些阈值。\n",
    "- **timestamp_granularities[]**（时间戳粒度，可选）：为此转录填充的时间戳粒度，默认为 segment。响应格式必须设置为 verbose_json 才能使用时间戳粒度。支持以下一个或两个选项：word 或 segment。注意：segment 时间戳不增加额外延迟，但生成 word 时间戳会增加额外延迟。\n",
    "\n",
    "返回值\n",
    "- 转录对象（Transcription Object）或详细转录对象（Verbose Transcription Object）。\n",
    "\n",
    "### 转录对象\n",
    "\n",
    "**Transcription Object**:\n",
    "```json\n",
    "{\n",
    "  \"text\": \"Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that.\"\n",
    "}\n",
    "```\n",
    "\n",
    "**Verbose Transcription Object**:\n",
    "```json\n",
    "{\n",
    "  \"task\": \"transcribe\",\n",
    "  \"language\": \"english\",\n",
    "  \"duration\": 8.470000267028809,\n",
    "  \"text\": \"The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.\",\n",
    "  \"segments\": [\n",
    "    {\n",
    "      \"id\": 0,\n",
    "      \"seek\": 0,\n",
    "      \"start\": 0.0,\n",
    "      \"end\": 3.319999933242798,\n",
    "      \"text\": \" The beach was a popular spot on a hot summer day.\",\n",
    "      \"tokens\": [\n",
    "        50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530\n",
    "      ],\n",
    "      \"temperature\": 0.0,\n",
    "      \"avg_logprob\": -0.2860786020755768,\n",
    "      \"compression_ratio\": 1.2363636493682861,\n",
    "      \"no_speech_prob\": 0.00985979475080967\n",
    "    },\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3150141f-f246-44e1-b6fe-43387d953783",
   "metadata": {},
   "source": [
    "### 使用 Whisper 实现中文转录\n",
    "\n",
    "将 TTS 配音的李云龙台词音频文件(liyunlong.mp3)发送给 Whisper 模型进行中文转录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84fcd642-213d-45b2-86c1-042657f5baa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "二营长,你他娘的意大利泡呢?给我拉来!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(         \n",
    "    # 代理地址，填写商家中转站或自建OpenAI代理\n",
    "    base_url='https://api.xiaoai.plus/v1' \n",
    ")\n",
    "\n",
    "audio_file= open(\"./audio/liyunlong.mp3\", \"rb\")\n",
    "\n",
    "transcription = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\", \n",
    "  file=audio_file\n",
    ")\n",
    "\n",
    "print(transcription.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6388a91-b426-44f1-bd1e-89a17b744b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94fa82fb-b9f4-478e-af4e-97744326ba22",
   "metadata": {},
   "source": [
    "## 语音翻译 API\n",
    "\n",
    "输入音频文件，返回翻译文本\n",
    "\n",
    "请求体\n",
    "- **file**（文件）：需要翻译的音频文件对象（不是文件名），支持以下格式：flac、mp3、mp4、mpeg、mpga、m4a、ogg、wav 或 webm。\n",
    "- **model**（'whisper-1'）：使用的模型 ID。目前只有由我们的开源 Whisper V2 模型驱动的 whisper-1 可用。\n",
    "- **prompt**（提示，可选）：可选文本，用于指导模型的风格或继续前一个音频片段。提示应为英文。\n",
    "- **response_format**（响应格式，可选）：转录输出的格式，默认为 json。可选的格式包括：json、text、srt、verbose_json 或 vtt。\n",
    "- **temperature**（温度，可选）：采样温度，范围从 0 到 1。较高的值，如 0.8，将使输出更随机，而较低的值，如 0.2，将使输出更集中和确定。如果设置为 0，模型将使用对数概率自动增加温度，直到达到特定阈值。\n",
    "\n",
    "返回值\n",
    "- **translated_text**: 翻译后的文本。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cd53e0-c069-4a6c-964d-c2d348781433",
   "metadata": {},
   "source": [
    "### 使用 Whisper 实现中文识别+翻译\n",
    "\n",
    "将 TTS 配音的李云龙台词音频文件(liyunlong.mp3)发送给 Whisper 模型进行翻译"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf456da9-56b8-4795-bf26-2379e1772c20",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"bind request body failed: Key: 'TextToSpeechRequest.Model' Error:Field validation for 'Model' failed on the 'required' tag\\nKey: 'TextToSpeechRequest.Input' Error:Field validation for 'Input' failed on the 'required' tag\\nKey: 'TextToSpeechRequest.Voice' Error:Field validation for 'Voice' failed on the 'required' tag (request id: ) (request id: 202407231153049935860743QYhaPAv)\", 'type': 'chat_api_error', 'param': '', 'code': 'bind_request_body_failed'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mBadRequestError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m audio_file\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./audio/liyunlong.mp3\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m translation \u001B[38;5;241m=\u001B[39m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maudio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranslations\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mwhisper-1\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maudio_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTranslate into English\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(translation\u001B[38;5;241m.\u001B[39mtext)\n",
      "File \u001B[1;32mD:\\Program_Files\\miniconda3\\envs\\langchain\\lib\\site-packages\\openai\\resources\\audio\\translations.py:100\u001B[0m, in \u001B[0;36mTranslations.create\u001B[1;34m(self, file, model, prompt, response_format, temperature, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;66;03m# It should be noted that the actual Content-Type header that will be\u001B[39;00m\n\u001B[0;32m     97\u001B[0m \u001B[38;5;66;03m# sent to the server will contain a `boundary` parameter, e.g.\u001B[39;00m\n\u001B[0;32m     98\u001B[0m \u001B[38;5;66;03m# multipart/form-data; boundary=---abc--\u001B[39;00m\n\u001B[0;32m     99\u001B[0m extra_headers \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mContent-Type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultipart/form-data\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m(extra_headers \u001B[38;5;129;01mor\u001B[39;00m {})}\n\u001B[1;32m--> 100\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    101\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/audio/translations\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    102\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtranslation_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTranslationCreateParams\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    103\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    104\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    105\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[0;32m    106\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    107\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mTranslation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    108\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Program_Files\\miniconda3\\envs\\langchain\\lib\\site-packages\\openai\\_base_client.py:1266\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1252\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[0;32m   1253\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1254\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1261\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1262\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[0;32m   1263\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[0;32m   1264\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[0;32m   1265\u001B[0m     )\n\u001B[1;32m-> 1266\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32mD:\\Program_Files\\miniconda3\\envs\\langchain\\lib\\site-packages\\openai\\_base_client.py:942\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[0;32m    933\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[0;32m    934\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    935\u001B[0m     cast_to: Type[ResponseT],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    940\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    941\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m--> 942\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    943\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    944\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    945\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    946\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    947\u001B[0m \u001B[43m        \u001B[49m\u001B[43mremaining_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremaining_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    948\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Program_Files\\miniconda3\\envs\\langchain\\lib\\site-packages\\openai\\_base_client.py:1046\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1043\u001B[0m         err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[0;32m   1045\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1046\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1048\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_response(\n\u001B[0;32m   1049\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[0;32m   1050\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1053\u001B[0m     stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[0;32m   1054\u001B[0m )\n",
      "\u001B[1;31mBadRequestError\u001B[0m: Error code: 400 - {'error': {'message': \"bind request body failed: Key: 'TextToSpeechRequest.Model' Error:Field validation for 'Model' failed on the 'required' tag\\nKey: 'TextToSpeechRequest.Input' Error:Field validation for 'Input' failed on the 'required' tag\\nKey: 'TextToSpeechRequest.Voice' Error:Field validation for 'Voice' failed on the 'required' tag (request id: ) (request id: 202407231153049935860743QYhaPAv)\", 'type': 'chat_api_error', 'param': '', 'code': 'bind_request_body_failed'}}"
     ]
    }
   ],
   "source": [
    "audio_file= open(\"./audio/liyunlong.mp3\", \"rb\")\n",
    "\n",
    "translation = client.audio.translations.create(\n",
    "    model=\"whisper-1\", \n",
    "    file=audio_file,\n",
    "    prompt=\"Translate into English\",\n",
    ")\n",
    "\n",
    "print(translation.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c25de24-8cdb-4335-9028-fa7eb35dd6be",
   "metadata": {},
   "source": [
    "### 使用 TTS 给李云龙英文版台词配音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "055a0016-9b49-4105-b64d-4ae3c4a543ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_file_path = \"./audio/liyunlong_en.mp3\"\n",
    "\n",
    "with client.audio.speech.with_streaming_response.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"onyx\",\n",
    "    input=translation.text\n",
    ") as response:\n",
    "    response.stream_to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004b6daa-6df7-42f3-93dd-ef4ce8d04ca9",
   "metadata": {},
   "source": [
    "### 使用 Whipser + TTS 生成郭德纲相声英文版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32bd206c-419f-4350-9eac-360b05c3a529",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"bind request body failed: Key: 'TextToSpeechRequest.Model' Error:Field validation for 'Model' failed on the 'required' tag\\nKey: 'TextToSpeechRequest.Input' Error:Field validation for 'Input' failed on the 'required' tag\\nKey: 'TextToSpeechRequest.Voice' Error:Field validation for 'Voice' failed on the 'required' tag (request id: ) (request id: 20240723143920807682616aNZIb0dB)\", 'type': 'chat_api_error', 'param': '', 'code': 'bind_request_body_failed'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mBadRequestError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m gdg_audio_file \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./audio/gdg.mp3\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      2\u001B[0m gdg_speech_file \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./audio/gdg_en.mp3\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 4\u001B[0m translation \u001B[38;5;241m=\u001B[39m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maudio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranslations\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m  \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgpt-4o\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m  \u001B[49m\u001B[43mfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgdg_audio_file\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(translation\u001B[38;5;241m.\u001B[39mtext)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m client\u001B[38;5;241m.\u001B[39maudio\u001B[38;5;241m.\u001B[39mspeech\u001B[38;5;241m.\u001B[39mwith_streaming_response\u001B[38;5;241m.\u001B[39mcreate(\n\u001B[0;32m     12\u001B[0m     model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtts-1\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     13\u001B[0m     voice\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124monyx\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m=\u001B[39mtranslation\u001B[38;5;241m.\u001B[39mtext\n\u001B[0;32m     15\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m response:\n",
      "File \u001B[1;32mD:\\Program_Files\\miniconda3\\envs\\langchain\\lib\\site-packages\\openai\\resources\\audio\\translations.py:100\u001B[0m, in \u001B[0;36mTranslations.create\u001B[1;34m(self, file, model, prompt, response_format, temperature, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;66;03m# It should be noted that the actual Content-Type header that will be\u001B[39;00m\n\u001B[0;32m     97\u001B[0m \u001B[38;5;66;03m# sent to the server will contain a `boundary` parameter, e.g.\u001B[39;00m\n\u001B[0;32m     98\u001B[0m \u001B[38;5;66;03m# multipart/form-data; boundary=---abc--\u001B[39;00m\n\u001B[0;32m     99\u001B[0m extra_headers \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mContent-Type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultipart/form-data\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m(extra_headers \u001B[38;5;129;01mor\u001B[39;00m {})}\n\u001B[1;32m--> 100\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    101\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/audio/translations\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    102\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtranslation_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTranslationCreateParams\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    103\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    104\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    105\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[0;32m    106\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    107\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mTranslation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    108\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Program_Files\\miniconda3\\envs\\langchain\\lib\\site-packages\\openai\\_base_client.py:1266\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1252\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[0;32m   1253\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1254\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1261\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1262\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[0;32m   1263\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[0;32m   1264\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[0;32m   1265\u001B[0m     )\n\u001B[1;32m-> 1266\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32mD:\\Program_Files\\miniconda3\\envs\\langchain\\lib\\site-packages\\openai\\_base_client.py:942\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[0;32m    933\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[0;32m    934\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    935\u001B[0m     cast_to: Type[ResponseT],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    940\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    941\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m--> 942\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    943\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    944\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    945\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    946\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    947\u001B[0m \u001B[43m        \u001B[49m\u001B[43mremaining_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremaining_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    948\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Program_Files\\miniconda3\\envs\\langchain\\lib\\site-packages\\openai\\_base_client.py:1046\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1043\u001B[0m         err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[0;32m   1045\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1046\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1048\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_response(\n\u001B[0;32m   1049\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[0;32m   1050\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1053\u001B[0m     stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[0;32m   1054\u001B[0m )\n",
      "\u001B[1;31mBadRequestError\u001B[0m: Error code: 400 - {'error': {'message': \"bind request body failed: Key: 'TextToSpeechRequest.Model' Error:Field validation for 'Model' failed on the 'required' tag\\nKey: 'TextToSpeechRequest.Input' Error:Field validation for 'Input' failed on the 'required' tag\\nKey: 'TextToSpeechRequest.Voice' Error:Field validation for 'Voice' failed on the 'required' tag (request id: ) (request id: 20240723143920807682616aNZIb0dB)\", 'type': 'chat_api_error', 'param': '', 'code': 'bind_request_body_failed'}}"
     ]
    }
   ],
   "source": [
    "gdg_audio_file = open(\"./audio/gdg.mp3\", \"rb\")\n",
    "gdg_speech_file = \"./audio/gdg_en.mp3\"\n",
    "\n",
    "translation = client.audio.translations.create(\n",
    "  model=\"gpt-4o\", \n",
    "  file=gdg_audio_file\n",
    ")\n",
    "\n",
    "print(translation.text)\n",
    "\n",
    "with client.audio.speech.with_streaming_response.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"onyx\",\n",
    "    input=translation.text\n",
    ") as response:\n",
    "    response.stream_to_file(gdg_speech_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5cbeca-187f-4121-b634-9ae8e2fadec8",
   "metadata": {},
   "source": [
    "### 使用 Whipser + TTS 生成B吧相声英文版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c8f3d7e-0d52-454b-84fa-ffcdb786864b",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"bind request body failed: Key: 'TextToSpeechRequest.Model' Error:Field validation for 'Model' failed on the 'required' tag\\nKey: 'TextToSpeechRequest.Input' Error:Field validation for 'Input' failed on the 'required' tag\\nKey: 'TextToSpeechRequest.Voice' Error:Field validation for 'Voice' failed on the 'required' tag (request id: ) (request id: 20240723143652499333505ipmqKLIi)\", 'type': 'chat_api_error', 'param': '', 'code': 'bind_request_body_failed'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mBadRequestError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[27], line 12\u001B[0m\n\u001B[0;32m      9\u001B[0m audio_file\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./audio/b_test.mp3\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     10\u001B[0m speech_file \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./audio/b_test_en.mp3\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 12\u001B[0m transcription \u001B[38;5;241m=\u001B[39m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maudio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranslations\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m  \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgpt-4o\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m  \u001B[49m\u001B[43mfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maudio_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m  \u001B[49m\u001B[43mprompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTranslate into English\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28mprint\u001B[39m(transcription\u001B[38;5;241m.\u001B[39mtext)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m client\u001B[38;5;241m.\u001B[39maudio\u001B[38;5;241m.\u001B[39mspeech\u001B[38;5;241m.\u001B[39mwith_streaming_response\u001B[38;5;241m.\u001B[39mcreate(\n\u001B[0;32m     21\u001B[0m     model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtts-1\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     22\u001B[0m     voice\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124monyx\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     23\u001B[0m     \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m=\u001B[39mtranscription\u001B[38;5;241m.\u001B[39mtext\n\u001B[0;32m     24\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m response:\n",
      "File \u001B[1;32mD:\\Program_Files\\miniconda3\\envs\\langchain\\lib\\site-packages\\openai\\resources\\audio\\translations.py:100\u001B[0m, in \u001B[0;36mTranslations.create\u001B[1;34m(self, file, model, prompt, response_format, temperature, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;66;03m# It should be noted that the actual Content-Type header that will be\u001B[39;00m\n\u001B[0;32m     97\u001B[0m \u001B[38;5;66;03m# sent to the server will contain a `boundary` parameter, e.g.\u001B[39;00m\n\u001B[0;32m     98\u001B[0m \u001B[38;5;66;03m# multipart/form-data; boundary=---abc--\u001B[39;00m\n\u001B[0;32m     99\u001B[0m extra_headers \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mContent-Type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultipart/form-data\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m(extra_headers \u001B[38;5;129;01mor\u001B[39;00m {})}\n\u001B[1;32m--> 100\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    101\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/audio/translations\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    102\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtranslation_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTranslationCreateParams\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    103\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    104\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    105\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[0;32m    106\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    107\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mTranslation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    108\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Program_Files\\miniconda3\\envs\\langchain\\lib\\site-packages\\openai\\_base_client.py:1266\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1252\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[0;32m   1253\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1254\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1261\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1262\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[0;32m   1263\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[0;32m   1264\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[0;32m   1265\u001B[0m     )\n\u001B[1;32m-> 1266\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32mD:\\Program_Files\\miniconda3\\envs\\langchain\\lib\\site-packages\\openai\\_base_client.py:942\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[0;32m    933\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[0;32m    934\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    935\u001B[0m     cast_to: Type[ResponseT],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    940\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    941\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m--> 942\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    943\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    944\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    945\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    946\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    947\u001B[0m \u001B[43m        \u001B[49m\u001B[43mremaining_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremaining_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    948\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Program_Files\\miniconda3\\envs\\langchain\\lib\\site-packages\\openai\\_base_client.py:1046\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1043\u001B[0m         err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[0;32m   1045\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1046\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1048\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_response(\n\u001B[0;32m   1049\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[0;32m   1050\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1053\u001B[0m     stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[0;32m   1054\u001B[0m )\n",
      "\u001B[1;31mBadRequestError\u001B[0m: Error code: 400 - {'error': {'message': \"bind request body failed: Key: 'TextToSpeechRequest.Model' Error:Field validation for 'Model' failed on the 'required' tag\\nKey: 'TextToSpeechRequest.Input' Error:Field validation for 'Input' failed on the 'required' tag\\nKey: 'TextToSpeechRequest.Voice' Error:Field validation for 'Voice' failed on the 'required' tag (request id: ) (request id: 20240723143652499333505ipmqKLIi)\", 'type': 'chat_api_error', 'param': '', 'code': 'bind_request_body_failed'}}"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(        \n",
    "    # 代理地址，填写商家中转站或自建OpenAI代理\n",
    "    base_url='https://api.xiaoai.plus/v1' \n",
    ")\n",
    "\n",
    "audio_file= open(\"./audio/b_test.mp3\", \"rb\")\n",
    "speech_file = \"./audio/b_test_en.mp3\"\n",
    "\n",
    "transcription = client.audio.translations.create(\n",
    "  model=\"gpt-4o\", \n",
    "  file=audio_file,\n",
    "  prompt=\"Translate into English\",\n",
    ")\n",
    "\n",
    "print(transcription.text)\n",
    "\n",
    "with client.audio.speech.with_streaming_response.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"onyx\",\n",
    "    input=transcription.text\n",
    ") as response:\n",
    "    response.stream_to_file(speech_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae579e8e-a197-426c-86f7-5ba0d1659ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
